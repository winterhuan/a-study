# Apache Flink æºç å­¦ä¹ ä»£ç ç¤ºä¾‹é›†

> **ç‰ˆæœ¬**: åŸºäº Apache Flink ä¸»åˆ†æ”¯
> **æ›´æ–°æ—¥æœŸ**: 2025-01-11
> **ç›®æ ‡**: é€šè¿‡å®Œæ•´ä»£ç ç¤ºä¾‹åŠ é€Ÿ Flink æºç å­¦ä¹ 

## ğŸ“– æ–‡æ¡£è¯´æ˜

æœ¬æ–‡æ¡£æä¾›äº†ä¸€ç³»åˆ—å®Œæ•´çš„ä»£ç ç¤ºä¾‹,æ¶µç›–:

- âœ… Test Harness çš„ä½¿ç”¨
- âœ… è‡ªå®šä¹‰ç®—å­çš„å®ç°å’Œæµ‹è¯•
- âœ… çŠ¶æ€ç®¡ç†çš„ä½¿ç”¨
- âœ… Checkpoint çš„æµ‹è¯•
- âœ… ä»æµ‹è¯•è·Ÿè¸ªåˆ°æºç çš„å®ä¾‹

æ‰€æœ‰ç¤ºä¾‹éƒ½å¯ä»¥ç›´æ¥è¿è¡Œ,å¸®åŠ©ä½ å¿«é€Ÿç†è§£ Flink çš„æ ¸å¿ƒæœºåˆ¶ã€‚

---

## ğŸ“‚ ç¤ºä¾‹ç´¢å¼•

| åºå· | ç¤ºä¾‹åç§° | éš¾åº¦ | æ¶µç›–çŸ¥è¯†ç‚¹ |
|------|---------|------|-----------|
| 1 | [WordCount å®Œæ•´åˆ†æ](#1-wordcount-å®Œæ•´åˆ†æ) | â­ | DataStream API, ç®—å­é“¾ |
| 2 | [ä½¿ç”¨ OneInputStreamOperatorTestHarness](#2-ä½¿ç”¨-oneinputstreamoperatortestharness) | â­â­ | æµ‹è¯•æ¡†æ¶åŸºç¡€ |
| 3 | [è‡ªå®šä¹‰ Map ç®—å­åŠæµ‹è¯•](#3-è‡ªå®šä¹‰-map-ç®—å­åŠæµ‹è¯•) | â­â­ | ç®—å­å®ç°, å•å…ƒæµ‹è¯• |
| 4 | [æœ‰çŠ¶æ€çš„è®¡æ•°å™¨ç®—å­](#4-æœ‰çŠ¶æ€çš„è®¡æ•°å™¨ç®—å­) | â­â­â­ | KeyedState, Checkpoint |
| 5 | [æ»‘åŠ¨çª—å£ Top-N](#5-æ»‘åŠ¨çª—å£-top-n) | â­â­â­ | çª—å£, ProcessFunction |
| 6 | [ä½¿ç”¨ StreamTaskMailboxTestHarness](#6-ä½¿ç”¨-streamtaskmailboxtestharness) | â­â­â­â­ | ä»»åŠ¡æµ‹è¯•, Mailbox æ¨¡å‹ |
| 7 | [Checkpoint å®Œæ•´æµç¨‹æµ‹è¯•](#7-checkpoint-å®Œæ•´æµç¨‹æµ‹è¯•) | â­â­â­â­ | CheckpointCoordinator |
| 8 | [è‡ªå®šä¹‰ StateBackend å®ç°](#8-è‡ªå®šä¹‰-statebackend-å®ç°) | â­â­â­â­â­ | çŠ¶æ€åç«¯, é«˜çº§ç‰¹æ€§ |
| 9 | [ä»æµ‹è¯•è·Ÿè¸ªåˆ°æºç å®ä¾‹](#9-ä»æµ‹è¯•è·Ÿè¸ªåˆ°æºç å®ä¾‹) | â­â­â­ | è°ƒè¯•æŠ€å·§ |
| 10 | [æ€§èƒ½æµ‹è¯•æ¡†æ¶](#10-æ€§èƒ½æµ‹è¯•æ¡†æ¶) | â­â­â­â­ | æ€§èƒ½åˆ†æ |

---

## 1. WordCount å®Œæ•´åˆ†æ

### ğŸ“ ç¤ºä¾‹è¯´æ˜

è¿™æ˜¯ Flink æœ€ç»å…¸çš„ç¤ºä¾‹,å±•ç¤ºäº†:

- StreamExecutionEnvironment çš„ä½¿ç”¨
- DataStream API åŸºæœ¬æ“ä½œ
- ç®—å­é“¾çš„å½¢æˆ
- æ‰¹æµç»Ÿä¸€çš„æ‰§è¡Œæ¨¡å¼

### ğŸ’» å®Œæ•´ä»£ç 

```java
package org.apache.flink.examples;

import org.apache.flink.api.common.RuntimeExecutionMode;
import org.apache.flink.api.common.functions.FlatMapFunction;
import org.apache.flink.api.java.tuple.Tuple2;
import org.apache.flink.streaming.api.datastream.DataStream;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.util.Collector;

/**
 * ç»å…¸çš„ WordCount ç¤ºä¾‹
 *
 * çŸ¥è¯†ç‚¹:
 * 1. StreamExecutionEnvironment çš„åˆ›å»ºå’Œé…ç½®
 * 2. æ•°æ®æºçš„åˆ›å»º (fromData)
 * 3. è½¬æ¢æ“ä½œ (flatMap, keyBy, sum)
 * 4. ç»“æœè¾“å‡º (print)
 * 5. ä½œä¸šæ‰§è¡Œ (execute)
 */
public class WordCountExample {

    public static void main(String[] args) throws Exception {
        // 1. åˆ›å»ºæ‰§è¡Œç¯å¢ƒ
        final StreamExecutionEnvironment env =
            StreamExecutionEnvironment.getExecutionEnvironment();

        // 2. è®¾ç½®è¿è¡Œæ¨¡å¼
        // STREAMING: æµå¼å¤„ç†,äº§ç”Ÿå¢é‡æ›´æ–°
        // BATCH: æ‰¹å¤„ç†,åªåœ¨æœ€åäº§ç”Ÿç»“æœ
        // AUTOMATIC: æ ¹æ®æ•°æ®æºè‡ªåŠ¨é€‰æ‹©
        env.setRuntimeMode(RuntimeExecutionMode.AUTOMATIC);

        // 3. è®¾ç½®å¹¶è¡Œåº¦(å¯é€‰)
        env.setParallelism(4);

        // 4. åˆ›å»ºæ•°æ®æº
        DataStream<String> text = env.fromData(
            "To be, or not to be,--that is the question:--",
            "Whether 'tis nobler in the mind to suffer",
            "The slings and arrows of outrageous fortune",
            "Or to take arms against a sea of troubles,"
        );

        // 5. æ•°æ®è½¬æ¢
        DataStream<Tuple2<String, Integer>> counts = text
            // flatMap: ä¸€å¯¹å¤šè½¬æ¢
            .flatMap(new Tokenizer())
            .name("tokenizer")  // è®¾ç½®ç®—å­åç§°,ä¾¿äºç›‘æ§
            // keyBy: æŒ‰ key åˆ†ç»„,è¿™é‡ŒæŒ‰å•è¯åˆ†ç»„
            .keyBy(value -> value.f0)
            // sum: èšåˆæ“ä½œ,ç´¯åŠ è®¡æ•°
            .sum(1)
            .name("counter");

        // 6. è¾“å‡ºç»“æœ
        counts.print().name("print-sink");

        // 7. æ‰§è¡Œä½œä¸š
        // æ³¨æ„: Flink æ˜¯æ‡’æ‰§è¡Œçš„,åªæœ‰è°ƒç”¨ execute() æ‰ä¼šçœŸæ­£è¿è¡Œ
        env.execute("WordCount Example");
    }

    /**
     * åˆ†è¯å™¨: å°†å¥å­æ‹†åˆ†æˆå•è¯
     *
     * å®ç° FlatMapFunction æ¥å£:
     * - è¾“å…¥: String (ä¸€è¡Œæ–‡æœ¬)
     * - è¾“å‡º: Tuple2<String, Integer> (å•è¯, è®¡æ•°)
     */
    public static final class Tokenizer
            implements FlatMapFunction<String, Tuple2<String, Integer>> {

        @Override
        public void flatMap(String value, Collector<Tuple2<String, Integer>> out) {
            // 1. è½¬å°å†™å¹¶æŒ‰éå•è¯å­—ç¬¦åˆ†å‰²
            String[] tokens = value.toLowerCase().split("\\W+");

            // 2. è¾“å‡ºæ¯ä¸ªå•è¯åŠå…¶åˆå§‹è®¡æ•° 1
            for (String token : tokens) {
                if (token.length() > 0) {
                    out.collect(new Tuple2<>(token, 1));
                }
            }
        }
    }
}
```

### ğŸ” æ‰§è¡Œæµç¨‹åˆ†æ

```
ç”¨æˆ·ä»£ç                         Flink å†…éƒ¨è½¬æ¢
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

env.fromData(...)           â†’ SourceTransformation
    â†“
.flatMap(new Tokenizer())   â†’ OneInputTransformation
    â†“                           (FlatMap ç®—å­)
.keyBy(value -> value.f0)   â†’ PartitionTransformation
    â†“                           (KeyBy ä¸æ˜¯ç®—å­,æ˜¯é‡åˆ†åŒº)
.sum(1)                     â†’ OneInputTransformation
    â†“                           (StreamGroupedReduce ç®—å­)
.print()                    â†’ SinkTransformation
    â†“                           (Print Sink)
env.execute()               â†’ ç”Ÿæˆ StreamGraph
                            â†’ ç”Ÿæˆ JobGraph (ç®—å­é“¾ä¼˜åŒ–)
                            â†’ æäº¤æ‰§è¡Œ
```

### ğŸ¯ ç®—å­é“¾åˆ†æ

åœ¨è¿™ä¸ªä¾‹å­ä¸­,ä»¥ä¸‹ç®—å­ä¼šè¢«é“¾åœ¨ä¸€èµ·:

```
Source â†’ FlatMap â†’ KeyBy â†’ Reduce â†’ Sink
         â”€â”€â”€â”€â”€â”€â”€â”€â”€é“¾1â”€â”€â”€â”€â”€â”€    â”€â”€â”€â”€â”€é“¾2â”€â”€â”€â”€
```

**é“¾ 1**: Source + FlatMap (æ»¡è¶³é“¾æ¡ä»¶)

- åŒä¸€å¹¶è¡Œåº¦
- åŒä¸€ Slot Sharing Group
- ForwardPartitioner

**é“¾ 2**: Reduce + Sink (æ»¡è¶³é“¾æ¡ä»¶)

**ä¸é“¾**: KeyBy æ˜¯åˆ†åŒºæ“ä½œ,ä¼šæ‰“æ–­ç®—å­é“¾

### ğŸ“š ä»è¿™ä¸ªä¾‹å­å­¦åˆ°çš„

1. **ä» `env.execute()` å…¥æ‰‹**:

   ```bash
   # è®¾ç½®æ–­ç‚¹
   StreamExecutionEnvironment.java:execute()

   # è§‚å¯Ÿè°ƒç”¨æ ˆ
   execute()
     â†’ executeAsync()
       â†’ getStreamGraph()
         â†’ StreamGraphGenerator.generate()
       â†’ PipelineExecutor.execute()
   ```

2. **æŸ¥çœ‹ç”Ÿæˆçš„ StreamGraph**:

   ```java
   StreamGraph streamGraph = env.getStreamGraph();
   System.out.println("Nodes: " + streamGraph.getStreamNodes().size());
   streamGraph.getStreamNodes().forEach((id, node) -> {
       System.out.println("Node " + id + ": " + node.getOperatorName());
   });
   ```

3. **ç†è§£ç®—å­ç±»å‹**:
   - `Source`: `SourceTransformation`
   - `FlatMap`: `OneInputStreamOperator`
   - `KeyBy`: `PartitionTransformation` (ä¸æ˜¯ç®—å­!)
   - `Sum`: `StreamGroupedReduce`
   - `Sink`: `SinkTransformation`

---

## 2. ä½¿ç”¨ OneInputStreamOperatorTestHarness

### ğŸ“ ç¤ºä¾‹è¯´æ˜

`OneInputStreamOperatorTestHarness` æ˜¯æµ‹è¯•å•è¾“å…¥ç®—å­æœ€å¸¸ç”¨çš„å·¥å…·,å¯ä»¥:

- ç‹¬ç«‹æµ‹è¯•ç®—å­é€»è¾‘
- æ§åˆ¶è¾“å…¥æ•°æ®å’Œæ—¶é—´
- éªŒè¯è¾“å‡ºç»“æœ
- æµ‹è¯•çŠ¶æ€å’Œ Checkpoint

### ğŸ’» å®Œæ•´ä»£ç 

```java
package org.apache.flink.test.examples;

import org.apache.flink.api.common.functions.MapFunction;
import org.apache.flink.streaming.api.operators.StreamMap;
import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;
import org.apache.flink.streaming.util.OneInputStreamOperatorTestHarness;
import org.junit.jupiter.api.Test;

import java.util.List;

import static org.assertj.core.api.Assertions.assertThat;

/**
 * OneInputStreamOperatorTestHarness ä½¿ç”¨ç¤ºä¾‹
 *
 * æµ‹è¯•ä¸€ä¸ªç®€å•çš„ Map ç®—å­
 */
public class MapOperatorTest {

    /**
     * æµ‹è¯•åŸºæœ¬åŠŸèƒ½: å­—ç¬¦ä¸²è½¬å¤§å†™
     */
    @Test
    public void testBasicMap() throws Exception {
        // 1. åˆ›å»ºç®—å­
        StreamMap<String, String> operator = new StreamMap<>(
            new MapFunction<String, String>() {
                @Override
                public String map(String value) {
                    return value.toUpperCase();
                }
            }
        );

        // 2. åˆ›å»ºæµ‹è¯• Harness
        OneInputStreamOperatorTestHarness<String, String> harness =
            new OneInputStreamOperatorTestHarness<>(operator);

        // 3. æ‰“å¼€ç®—å­(åˆå§‹åŒ–)
        harness.open();

        // 4. è¾“å…¥æµ‹è¯•æ•°æ®
        harness.processElement(new StreamRecord<>("hello"));
        harness.processElement(new StreamRecord<>("world"));

        // 5. è·å–è¾“å‡ºç»“æœ
        List<StreamRecord<String>> output = harness.extractOutputStreamRecords();

        // 6. éªŒè¯ç»“æœ
        assertThat(output).hasSize(2);
        assertThat(output.get(0).getValue()).isEqualTo("HELLO");
        assertThat(output.get(1).getValue()).isEqualTo("WORLD");

        // 7. å…³é—­ç®—å­
        harness.close();
    }

    /**
     * æµ‹è¯•å¸¦æ—¶é—´æˆ³çš„æ•°æ®å¤„ç†
     */
    @Test
    public void testMapWithTimestamp() throws Exception {
        StreamMap<String, String> operator = new StreamMap<>(
            value -> value.toUpperCase()
        );

        OneInputStreamOperatorTestHarness<String, String> harness =
            new OneInputStreamOperatorTestHarness<>(operator);

        harness.open();

        // è¾“å…¥å¸¦æ—¶é—´æˆ³çš„æ•°æ®
        harness.processElement(new StreamRecord<>("hello", 1000L));
        harness.processElement(new StreamRecord<>("world", 2000L));

        List<StreamRecord<String>> output = harness.extractOutputStreamRecords();

        // éªŒè¯æ—¶é—´æˆ³è¢«ä¿ç•™
        assertThat(output.get(0).getTimestamp()).isEqualTo(1000L);
        assertThat(output.get(1).getTimestamp()).isEqualTo(2000L);

        harness.close();
    }

    /**
     * æµ‹è¯• Watermark å¤„ç†
     */
    @Test
    public void testMapWithWatermark() throws Exception {
        StreamMap<String, String> operator = new StreamMap<>(
            value -> value.toUpperCase()
        );

        OneInputStreamOperatorTestHarness<String, String> harness =
            new OneInputStreamOperatorTestHarness<>(operator);

        harness.open();

        // è¾“å…¥æ•°æ®å’Œ Watermark
        harness.processElement(new StreamRecord<>("hello", 1000L));
        harness.processWatermark(new org.apache.flink.streaming.api.watermark.Watermark(1500L));
        harness.processElement(new StreamRecord<>("world", 2000L));

        // è·å–æ‰€æœ‰è¾“å‡º(åŒ…æ‹¬ Watermark)
        List<Object> output = harness.getOutput();

        // éªŒè¯è¾“å‡ºé¡ºåº
        assertThat(output).hasSize(3);
        assertThat(output.get(0)).isInstanceOf(StreamRecord.class);
        assertThat(output.get(1)).isInstanceOf(org.apache.flink.streaming.api.watermark.Watermark.class);
        assertThat(output.get(2)).isInstanceOf(StreamRecord.class);

        harness.close();
    }
}
```

### ğŸ” Test Harness å·¥ä½œåŸç†

```java
// 1. åˆ›å»º Mock ç¯å¢ƒ
OneInputStreamOperatorTestHarness å†…éƒ¨:
â”œâ”€â”€ StreamMockEnvironment: æ¨¡æ‹Ÿæ‰§è¡Œç¯å¢ƒ
â”œâ”€â”€ StreamConfig: ç®—å­é…ç½®
â”œâ”€â”€ Output Collector: æ”¶é›†è¾“å‡º
â””â”€â”€ Time Service: æ—¶é—´æœåŠ¡

// 2. ç®—å­ç”Ÿå‘½å‘¨æœŸ
harness.open()              â†’ operator.setup()
                            â†’ operator.initializeState()
                            â†’ operator.open()

harness.processElement()    â†’ operator.processElement()

harness.close()             â†’ operator.close()
                            â†’ operator.dispose()

// 3. æ•°æ®æµè½¬
è¾“å…¥æ•°æ® â†’ processElement()
         â†’ operator.processElement()
         â†’ output.collect()
         â†’ outputList.add()
```

### ğŸ“š å…³é”® API

| æ–¹æ³• | ä½œç”¨ | ç¤ºä¾‹ |
|------|------|------|
| `open()` | åˆå§‹åŒ–ç®—å­ | `harness.open()` |
| `processElement()` | è¾“å…¥æ•°æ® | `harness.processElement(new StreamRecord<>("data"))` |
| `processWatermark()` | è¾“å…¥ Watermark | `harness.processWatermark(new Watermark(1000L))` |
| `extractOutputStreamRecords()` | è·å–è¾“å‡ºè®°å½• | `List<StreamRecord> output = harness.extractOutputStreamRecords()` |
| `getOutput()` | è·å–æ‰€æœ‰è¾“å‡º | `List<Object> output = harness.getOutput()` |
| `close()` | å…³é—­ç®—å­ | `harness.close()` |

---

## 3. è‡ªå®šä¹‰ Map ç®—å­åŠæµ‹è¯•

### ğŸ“ ç¤ºä¾‹è¯´æ˜

å±•ç¤ºå¦‚ä½•:

- å®ç°è‡ªå®šä¹‰ç®—å­
- ç»§æ‰¿ `AbstractStreamOperator`
- ç¼–å†™å®Œæ•´çš„å•å…ƒæµ‹è¯•
- å¤„ç†å¼‚å¸¸æƒ…å†µ

### ğŸ’» å®Œæ•´ä»£ç 

```java
package org.apache.flink.examples.custom;

import org.apache.flink.configuration.Configuration;
import org.apache.flink.streaming.api.operators.AbstractStreamOperator;
import org.apache.flink.streaming.api.operators.OneInputStreamOperator;
import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;

/**
 * è‡ªå®šä¹‰ Map ç®—å­: æ·»åŠ å‰ç¼€å¹¶è½¬å¤§å†™
 *
 * ç»§æ‰¿å…³ç³»:
 * AbstractStreamOperator (åŸºç±»)
 *   â†“
 * PrefixUpperCaseOperator (è‡ªå®šä¹‰ç®—å­)
 *
 * å®ç°æ¥å£:
 * OneInputStreamOperator (å•è¾“å…¥ç®—å­æ¥å£)
 */
public class PrefixUpperCaseOperator
        extends AbstractStreamOperator<String>
        implements OneInputStreamOperator<String, String> {

    private static final long serialVersionUID = 1L;

    // é…ç½®å‚æ•°
    private final String prefix;

    // è¿è¡Œæ—¶çŠ¶æ€
    private transient long processedCount;

    public PrefixUpperCaseOperator(String prefix) {
        this.prefix = prefix;
    }

    /**
     * ç®—å­åˆå§‹åŒ–
     * åœ¨ç®—å­å¯åŠ¨æ—¶è°ƒç”¨ä¸€æ¬¡
     */
    @Override
    public void open() throws Exception {
        super.open();
        this.processedCount = 0;

        // å¯ä»¥åœ¨è¿™é‡Œ:
        // 1. åˆå§‹åŒ–å¤–éƒ¨è¿æ¥
        // 2. åŠ è½½é…ç½®
        // 3. æ³¨å†Œ Metrics

        getRuntimeContext().getMetricGroup()
            .counter("processedElements");
    }

    /**
     * å¤„ç†æ¯ä¸€ä¸ªè¾“å…¥å…ƒç´ 
     * è¿™æ˜¯ç®—å­çš„æ ¸å¿ƒé€»è¾‘
     */
    @Override
    public void processElement(StreamRecord<String> element) throws Exception {
        // 1. è·å–è¾“å…¥å€¼
        String value = element.getValue();

        // 2. æ‰§è¡Œè½¬æ¢é€»è¾‘
        String result = prefix + value.toUpperCase();

        // 3. è¾“å‡ºç»“æœ(ä¿ç•™åŸå§‹æ—¶é—´æˆ³)
        output.collect(element.replace(result));

        // 4. æ›´æ–°è®¡æ•°å™¨
        processedCount++;
    }

    /**
     * ç®—å­å…³é—­
     * åœ¨ç®—å­åœæ­¢æ—¶è°ƒç”¨
     */
    @Override
    public void close() throws Exception {
        super.close();

        // å¯ä»¥åœ¨è¿™é‡Œ:
        // 1. å…³é—­å¤–éƒ¨è¿æ¥
        // 2. æ¸…ç†èµ„æº
        // 3. è¾“å‡ºç»Ÿè®¡ä¿¡æ¯

        System.out.println("Processed " + processedCount + " elements");
    }
}
```

### ğŸ§ª å®Œæ•´æµ‹è¯•ä»£ç 

```java
package org.apache.flink.examples.custom;

import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;
import org.apache.flink.streaming.util.OneInputStreamOperatorTestHarness;
import org.junit.jupiter.api.Test;

import java.util.List;

import static org.assertj.core.api.Assertions.assertThat;
import static org.assertj.core.api.Assertions.assertThatThrownBy;

/**
 * PrefixUpperCaseOperator çš„å®Œæ•´æµ‹è¯•
 */
public class PrefixUpperCaseOperatorTest {

    /**
     * æµ‹è¯•æ­£å¸¸æƒ…å†µ
     */
    @Test
    public void testNormalCase() throws Exception {
        // 1. åˆ›å»ºç®—å­å®ä¾‹
        PrefixUpperCaseOperator operator = new PrefixUpperCaseOperator("[PREFIX]");

        // 2. åˆ›å»ºæµ‹è¯• Harness
        OneInputStreamOperatorTestHarness<String, String> harness =
            new OneInputStreamOperatorTestHarness<>(operator);

        // 3. æ‰“å¼€ç®—å­
        harness.open();

        // 4. è¾“å…¥æµ‹è¯•æ•°æ®
        harness.processElement(new StreamRecord<>("hello"));
        harness.processElement(new StreamRecord<>("world"));

        // 5. è·å–è¾“å‡º
        List<StreamRecord<String>> output = harness.extractOutputStreamRecords();

        // 6. éªŒè¯ç»“æœ
        assertThat(output).hasSize(2);
        assertThat(output.get(0).getValue()).isEqualTo("[PREFIX]HELLO");
        assertThat(output.get(1).getValue()).isEqualTo("[PREFIX]WORLD");

        // 7. å…³é—­ç®—å­
        harness.close();
    }

    /**
     * æµ‹è¯•ç©ºå­—ç¬¦ä¸²
     */
    @Test
    public void testEmptyString() throws Exception {
        PrefixUpperCaseOperator operator = new PrefixUpperCaseOperator("[PREFIX]");
        OneInputStreamOperatorTestHarness<String, String> harness =
            new OneInputStreamOperatorTestHarness<>(operator);

        harness.open();

        // è¾“å…¥ç©ºå­—ç¬¦ä¸²
        harness.processElement(new StreamRecord<>(""));

        List<StreamRecord<String>> output = harness.extractOutputStreamRecords();

        // éªŒè¯: ç©ºå­—ç¬¦ä¸²ä¹Ÿä¼šè¢«å¤„ç†
        assertThat(output).hasSize(1);
        assertThat(output.get(0).getValue()).isEqualTo("[PREFIX]");

        harness.close();
    }

    /**
     * æµ‹è¯•æ—¶é—´æˆ³ä¿ç•™
     */
    @Test
    public void testTimestampPreservation() throws Exception {
        PrefixUpperCaseOperator operator = new PrefixUpperCaseOperator("[PREFIX]");
        OneInputStreamOperatorTestHarness<String, String> harness =
            new OneInputStreamOperatorTestHarness<>(operator);

        harness.open();

        // è¾“å…¥å¸¦æ—¶é—´æˆ³çš„æ•°æ®
        long timestamp = 123456789L;
        harness.processElement(new StreamRecord<>("hello", timestamp));

        List<StreamRecord<String>> output = harness.extractOutputStreamRecords();

        // éªŒè¯: æ—¶é—´æˆ³è¢«ä¿ç•™
        assertThat(output.get(0).getTimestamp()).isEqualTo(timestamp);

        harness.close();
    }

    /**
     * æµ‹è¯•ç©ºå‰ç¼€
     */
    @Test
    public void testEmptyPrefix() throws Exception {
        PrefixUpperCaseOperator operator = new PrefixUpperCaseOperator("");
        OneInputStreamOperatorTestHarness<String, String> harness =
            new OneInputStreamOperatorTestHarness<>(operator);

        harness.open();
        harness.processElement(new StreamRecord<>("hello"));

        List<StreamRecord<String>> output = harness.extractOutputStreamRecords();

        // éªŒè¯: åªè½¬å¤§å†™,æ²¡æœ‰å‰ç¼€
        assertThat(output.get(0).getValue()).isEqualTo("HELLO");

        harness.close();
    }

    /**
     * æµ‹è¯•ç‰¹æ®Šå­—ç¬¦
     */
    @Test
    public void testSpecialCharacters() throws Exception {
        PrefixUpperCaseOperator operator = new PrefixUpperCaseOperator("[PREFIX]");
        OneInputStreamOperatorTestHarness<String, String> harness =
            new OneInputStreamOperatorTestHarness<>(operator);

        harness.open();

        // è¾“å…¥åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„å­—ç¬¦ä¸²
        harness.processElement(new StreamRecord<>("hello@world#123"));

        List<StreamRecord<String>> output = harness.extractOutputStreamRecords();

        // éªŒè¯: ç‰¹æ®Šå­—ç¬¦ä¹Ÿè¢«è½¬å¤§å†™
        assertThat(output.get(0).getValue()).isEqualTo("[PREFIX]HELLO@WORLD#123");

        harness.close();
    }

    /**
     * æµ‹è¯•å¤šæ¡æ•°æ®å¤„ç†
     */
    @Test
    public void testMultipleElements() throws Exception {
        PrefixUpperCaseOperator operator = new PrefixUpperCaseOperator("[PREFIX]");
        OneInputStreamOperatorTestHarness<String, String> harness =
            new OneInputStreamOperatorTestHarness<>(operator);

        harness.open();

        // è¾“å…¥å¤šæ¡æ•°æ®
        for (int i = 0; i < 100; i++) {
            harness.processElement(new StreamRecord<>("data" + i));
        }

        List<StreamRecord<String>> output = harness.extractOutputStreamRecords();

        // éªŒè¯: æ‰€æœ‰æ•°æ®éƒ½è¢«æ­£ç¡®å¤„ç†
        assertThat(output).hasSize(100);
        for (int i = 0; i < 100; i++) {
            assertThat(output.get(i).getValue()).isEqualTo("[PREFIX]DATA" + i);
        }

        harness.close();
    }
}
```

### ğŸ¯ å­¦ä¹ é‡ç‚¹

1. **ç®—å­ç”Ÿå‘½å‘¨æœŸ**:

   ```
   æ„é€ å‡½æ•° â†’ open() â†’ processElement() â†’ close()
   ```

2. **å¦‚ä½•è¾“å‡ºæ•°æ®**:

   ```java
   // æ–¹å¼1: ä¿ç•™åŸå§‹æ—¶é—´æˆ³
   output.collect(element.replace(newValue));

   // æ–¹å¼2: ä½¿ç”¨å½“å‰æ—¶é—´æˆ³
   output.collect(new StreamRecord<>(newValue));
   ```

3. **å¦‚ä½•æ³¨å†Œ Metrics**:

   ```java
   getRuntimeContext().getMetricGroup()
       .counter("myCounter")
       .inc();
   ```

4. **æµ‹è¯•çš„å®Œæ•´æ€§**:
   - âœ… æ­£å¸¸æƒ…å†µ
   - âœ… è¾¹ç•Œæƒ…å†µ(ç©ºå­—ç¬¦ä¸²)
   - âœ… æ—¶é—´æˆ³å¤„ç†
   - âœ… ç‰¹æ®Šå­—ç¬¦
   - âœ… å¤§é‡æ•°æ®

---

## 4. æœ‰çŠ¶æ€çš„è®¡æ•°å™¨ç®—å­

### ğŸ“ ç¤ºä¾‹è¯´æ˜

å±•ç¤ºå¦‚ä½•:

- ä½¿ç”¨ KeyedState
- å®ç° Checkpoint
- æµ‹è¯•çŠ¶æ€çš„æŒä¹…åŒ–å’Œæ¢å¤

### ğŸ’» å®Œæ•´ä»£ç 

```java
package org.apache.flink.examples.stateful;

import org.apache.flink.api.common.functions.RichFlatMapFunction;
import org.apache.flink.api.common.state.ValueState;
import org.apache.flink.api.common.state.ValueStateDescriptor;
import org.apache.flink.api.common.typeinfo.Types;
import org.apache.flink.api.java.tuple.Tuple2;
import org.apache.flink.configuration.Configuration;
import org.apache.flink.util.Collector;

/**
 * æœ‰çŠ¶æ€çš„è®¡æ•°å™¨: ç»Ÿè®¡æ¯ä¸ª key å‡ºç°çš„æ¬¡æ•°
 *
 * ä½¿ç”¨ ValueState å­˜å‚¨è®¡æ•°
 * æ”¯æŒ Checkpoint å’Œæ•…éšœæ¢å¤
 */
public class StatefulCounter
        extends RichFlatMapFunction<String, Tuple2<String, Long>> {

    private static final long serialVersionUID = 1L;

    // çŠ¶æ€å¥æŸ„
    private transient ValueState<Long> countState;

    @Override
    public void open(Configuration parameters) throws Exception {
        super.open(parameters);

        // åˆ›å»ºçŠ¶æ€æè¿°ç¬¦
        ValueStateDescriptor<Long> descriptor = new ValueStateDescriptor<>(
            "count-state",  // çŠ¶æ€åç§°
            Types.LONG      // çŠ¶æ€ç±»å‹
        );

        // è·å–çŠ¶æ€å¥æŸ„
        countState = getRuntimeContext().getState(descriptor);
    }

    @Override
    public void flatMap(String key, Collector<Tuple2<String, Long>> out) throws Exception {
        // 1. è¯»å–å½“å‰è®¡æ•°(å¦‚æœä¸å­˜åœ¨åˆ™ä¸º null)
        Long currentCount = countState.value();

        // 2. å¢åŠ è®¡æ•°
        if (currentCount == null) {
            currentCount = 0L;
        }
        currentCount++;

        // 3. æ›´æ–°çŠ¶æ€
        countState.update(currentCount);

        // 4. è¾“å‡ºç»“æœ
        out.collect(new Tuple2<>(key, currentCount));
    }
}
```

### ğŸ§ª å®Œæ•´æµ‹è¯•ä»£ç 

```java
package org.apache.flink.examples.stateful;

import org.apache.flink.api.common.typeinfo.Types;
import org.apache.flink.api.java.tuple.Tuple2;
import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;
import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;
import org.apache.flink.streaming.util.KeyedOneInputStreamOperatorTestHarness;
import org.apache.flink.streaming.util.OneInputStreamOperatorTestHarness;
import org.junit.jupiter.api.Test;

import java.util.List;

import static org.assertj.core.api.Assertions.assertThat;

/**
 * StatefulCounter çš„å®Œæ•´æµ‹è¯•
 * åŒ…å«çŠ¶æ€å’Œ Checkpoint æµ‹è¯•
 */
public class StatefulCounterTest {

    /**
     * æµ‹è¯•åŸºæœ¬è®¡æ•°åŠŸèƒ½
     */
    @Test
    public void testBasicCounting() throws Exception {
        // 1. åˆ›å»º KeyedTestHarness (ç”¨äºæµ‹è¯• KeyedState)
        KeyedOneInputStreamOperatorTestHarness<String, String, Tuple2<String, Long>> harness =
            new KeyedOneInputStreamOperatorTestHarness<>(
                new StreamFlatMap<>(new StatefulCounter()),
                key -> key,  // KeySelector
                Types.STRING  // Key ç±»å‹
            );

        // 2. æ‰“å¼€ç®—å­
        harness.open();

        // 3. è¾“å…¥æµ‹è¯•æ•°æ®(ç›¸åŒçš„ key)
        harness.processElement("hello", 1000L);
        harness.processElement("hello", 2000L);
        harness.processElement("hello", 3000L);

        // 4. è·å–è¾“å‡º
        List<Tuple2<String, Long>> output = harness.extractOutputValues();

        // 5. éªŒè¯: è®¡æ•°é€’å¢
        assertThat(output).hasSize(3);
        assertThat(output.get(0).f1).isEqualTo(1L);
        assertThat(output.get(1).f1).isEqualTo(2L);
        assertThat(output.get(2).f1).isEqualTo(3L);

        harness.close();
    }

    /**
     * æµ‹è¯•å¤šä¸ª key
     */
    @Test
    public void testMultipleKeys() throws Exception {
        KeyedOneInputStreamOperatorTestHarness<String, String, Tuple2<String, Long>> harness =
            new KeyedOneInputStreamOperatorTestHarness<>(
                new StreamFlatMap<>(new StatefulCounter()),
                key -> key,
                Types.STRING
            );

        harness.open();

        // è¾“å…¥ä¸åŒçš„ key
        harness.processElement("hello", 1000L);
        harness.processElement("world", 1500L);
        harness.processElement("hello", 2000L);
        harness.processElement("world", 2500L);
        harness.processElement("hello", 3000L);

        List<Tuple2<String, Long>> output = harness.extractOutputValues();

        // éªŒè¯: æ¯ä¸ª key ç‹¬ç«‹è®¡æ•°
        assertThat(output).hasSize(5);
        assertThat(output.get(0)).isEqualTo(new Tuple2<>("hello", 1L));
        assertThat(output.get(1)).isEqualTo(new Tuple2<>("world", 1L));
        assertThat(output.get(2)).isEqualTo(new Tuple2<>("hello", 2L));
        assertThat(output.get(3)).isEqualTo(new Tuple2<>("world", 2L));
        assertThat(output.get(4)).isEqualTo(new Tuple2<>("hello", 3L));

        harness.close();
    }

    /**
     * æµ‹è¯• Checkpoint å’ŒçŠ¶æ€æ¢å¤
     *
     * è¿™æ˜¯æœ€é‡è¦çš„æµ‹è¯•!
     */
    @Test
    public void testCheckpointAndRestore() throws Exception {
        KeyedOneInputStreamOperatorTestHarness<String, String, Tuple2<String, Long>> harness =
            new KeyedOneInputStreamOperatorTestHarness<>(
                new StreamFlatMap<>(new StatefulCounter()),
                key -> key,
                Types.STRING
            );

        harness.open();

        // ç¬¬ä¸€é˜¶æ®µ: å¤„ç†ä¸€äº›æ•°æ®
        harness.processElement("hello", 1000L);
        harness.processElement("world", 1500L);
        harness.processElement("hello", 2000L);

        // è§¦å‘ Checkpoint,ä¿å­˜çŠ¶æ€å¿«ç…§
        OperatorSubtaskState snapshot = harness.snapshot(1L, 2000L);

        // æ¸…ç†è¾“å‡º
        harness.extractOutputValues();

        // å…³é—­ Harness
        harness.close();

        // ============ æ¨¡æ‹Ÿæ•…éšœæ¢å¤ ============

        // åˆ›å»ºæ–°çš„ Harness
        KeyedOneInputStreamOperatorTestHarness<String, String, Tuple2<String, Long>> restoredHarness =
            new KeyedOneInputStreamOperatorTestHarness<>(
                new StreamFlatMap<>(new StatefulCounter()),
                key -> key,
                Types.STRING
            );

        // ä»å¿«ç…§æ¢å¤çŠ¶æ€
        restoredHarness.initializeState(snapshot);
        restoredHarness.open();

        // ç¬¬äºŒé˜¶æ®µ: ç»§ç»­å¤„ç†æ•°æ®
        restoredHarness.processElement("hello", 3000L);  // åº”è¯¥æ˜¯ 3
        restoredHarness.processElement("world", 3500L);  // åº”è¯¥æ˜¯ 2

        List<Tuple2<String, Long>> output = restoredHarness.extractOutputValues();

        // éªŒè¯: çŠ¶æ€è¢«æ­£ç¡®æ¢å¤
        assertThat(output).hasSize(2);
        assertThat(output.get(0)).isEqualTo(new Tuple2<>("hello", 3L));  // æ¢å¤åç»§ç»­è®¡æ•°
        assertThat(output.get(1)).isEqualTo(new Tuple2<>("world", 2L));

        restoredHarness.close();
    }

    /**
     * æµ‹è¯•å¤šæ¬¡ Checkpoint
     */
    @Test
    public void testMultipleCheckpoints() throws Exception {
        KeyedOneInputStreamOperatorTestHarness<String, String, Tuple2<String, Long>> harness =
            new KeyedOneInputStreamOperatorTestHarness<>(
                new StreamFlatMap<>(new StatefulCounter()),
                key -> key,
                Types.STRING
            );

        harness.open();

        // ç¬¬ä¸€ä¸ª Checkpoint
        harness.processElement("hello", 1000L);
        OperatorSubtaskState snapshot1 = harness.snapshot(1L, 1000L);

        // ç¬¬äºŒä¸ª Checkpoint
        harness.processElement("hello", 2000L);
        OperatorSubtaskState snapshot2 = harness.snapshot(2L, 2000L);

        // ç¬¬ä¸‰ä¸ª Checkpoint
        harness.processElement("hello", 3000L);
        OperatorSubtaskState snapshot3 = harness.snapshot(3L, 3000L);

        harness.close();

        // ä»ç¬¬äºŒä¸ª Checkpoint æ¢å¤
        KeyedOneInputStreamOperatorTestHarness<String, String, Tuple2<String, Long>> restoredHarness =
            new KeyedOneInputStreamOperatorTestHarness<>(
                new StreamFlatMap<>(new StatefulCounter()),
                key -> key,
                Types.STRING
            );

        restoredHarness.initializeState(snapshot2);
        restoredHarness.open();

        restoredHarness.processElement("hello", 4000L);

        List<Tuple2<String, Long>> output = restoredHarness.extractOutputValues();

        // éªŒè¯: ä»ç¬¬äºŒä¸ª Checkpoint æ¢å¤,è®¡æ•°åº”è¯¥æ˜¯ 3
        assertThat(output.get(0).f1).isEqualTo(3L);

        restoredHarness.close();
    }
}
```

### ğŸ¯ å­¦ä¹ é‡ç‚¹

1. **çŠ¶æ€çš„ä½¿ç”¨**:

   ```java
   // 1. å®šä¹‰çŠ¶æ€æè¿°ç¬¦
   ValueStateDescriptor<Long> descriptor =
       new ValueStateDescriptor<>("name", Types.LONG);

   // 2. è·å–çŠ¶æ€å¥æŸ„
   ValueState<Long> state = getRuntimeContext().getState(descriptor);

   // 3. è¯»å–çŠ¶æ€
   Long value = state.value();

   // 4. æ›´æ–°çŠ¶æ€
   state.update(newValue);

   // 5. æ¸…é™¤çŠ¶æ€
   state.clear();
   ```

2. **Checkpoint æµ‹è¯•æµç¨‹**:

   ```java
   // 1. å¤„ç†æ•°æ®
   harness.processElement(...);

   // 2. è§¦å‘ Checkpoint
   OperatorSubtaskState snapshot = harness.snapshot(checkpointId, timestamp);

   // 3. å…³é—­åŸ Harness
   harness.close();

   // 4. åˆ›å»ºæ–° Harness
   newHarness = new ...();

   // 5. æ¢å¤çŠ¶æ€
   newHarness.initializeState(snapshot);
   newHarness.open();

   // 6. ç»§ç»­å¤„ç†æ•°æ®
   newHarness.processElement(...);
   ```

3. **KeyedTestHarness vs OneInputTestHarness**:
   - `KeyedOneInputStreamOperatorTestHarness`: ç”¨äºæµ‹è¯• KeyedState
   - `OneInputStreamOperatorTestHarness`: ç”¨äºæµ‹è¯•æ— çŠ¶æ€ç®—å­

---

**[ç”±äºç¯‡å¹…é™åˆ¶,åç»­ç¤ºä¾‹å°†åœ¨ä¸‹ä¸€éƒ¨åˆ†ç»§ç»­...]**

**å·²åŒ…å«çš„ç¤ºä¾‹**:

1. âœ… WordCount å®Œæ•´åˆ†æ
2. âœ… OneInputStreamOperatorTestHarness ä½¿ç”¨
3. âœ… è‡ªå®šä¹‰ Map ç®—å­åŠæµ‹è¯•
4. âœ… æœ‰çŠ¶æ€çš„è®¡æ•°å™¨ç®—å­

**å¾…è¡¥å……çš„ç¤ºä¾‹** (å°†åœ¨ flink-test-index.md æˆ–åç»­æ›´æ–°ä¸­æä¾›):
5. æ»‘åŠ¨çª—å£ Top-N
6. StreamTaskMailboxTestHarness ä½¿ç”¨
7. Checkpoint å®Œæ•´æµç¨‹æµ‹è¯•
8. è‡ªå®šä¹‰ StateBackend
9. ä»æµ‹è¯•è·Ÿè¸ªåˆ°æºç å®ä¾‹
10. æ€§èƒ½æµ‹è¯•æ¡†æ¶

---

## ğŸ“ å¦‚ä½•ä½¿ç”¨è¿™äº›ç¤ºä¾‹

### 1. ç›´æ¥è¿è¡Œ

```bash
# å¤åˆ¶ä»£ç åˆ°ä½ çš„é¡¹ç›®
# æ·»åŠ å¿…è¦çš„ä¾èµ–
# è¿è¡Œæµ‹è¯•
mvn test
```

### 2. è°ƒè¯•å­¦ä¹ 

```
1. åœ¨å…³é”®ä½ç½®è®¾ç½®æ–­ç‚¹
2. å•æ­¥æ‰§è¡Œ,è§‚å¯Ÿå˜é‡
3. è·³è½¬åˆ° Flink æºç 
4. ç†è§£æ‰§è¡Œæµç¨‹
```

### 3. ä¿®æ”¹å®éªŒ

```
1. ä¿®æ”¹ç®—å­é€»è¾‘
2. æ·»åŠ æ–°çš„æµ‹è¯•ç”¨ä¾‹
3. éªŒè¯ä½ çš„ç†è§£
4. è®°å½•å­¦ä¹ ç¬”è®°
```

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [Flink æºç é˜…è¯»æŒ‡å—](./flink-source-reading-guide.md) - å®Œæ•´çš„å­¦ä¹ è·¯çº¿
- [Flink å­¦ä¹ è®¡åˆ’è¡¨](./flink-learning-schedule.md) - 12å‘¨å­¦ä¹ è®¡åˆ’
- [Flink æµ‹è¯•æ–‡ä»¶ç´¢å¼•](./flink-test-index.md) - æµ‹è¯•æ–‡ä»¶é€ŸæŸ¥

---

**ç‰ˆæœ¬å†å²**:

- v1.0 (2025-01-11): åˆå§‹ç‰ˆæœ¬,åŒ…å«å‰ 4 ä¸ªæ ¸å¿ƒç¤ºä¾‹
- åç»­ç‰ˆæœ¬å°†è¡¥å……æ›´å¤šé«˜çº§ç¤ºä¾‹
